{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EENlZvOtPDZ6"
   },
   "source": [
    "# Квантование с Pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hbiiMcdNJI--"
   },
   "outputs": [],
   "source": [
    "#!pip3 install torch==1.5.0 torchvision==1.6.0\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.quantization\n",
    "from torch.quantization import QuantStub, DeQuantStub\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCaMDWYArEXO"
   },
   "source": [
    "Загрузим данные MNIST для обучения и тестирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "paBliKgoU6Rm"
   },
   "outputs": [],
   "source": [
    "args={}\n",
    "args['batch_size']=500\n",
    "args['test_batch_size']=500\n",
    "args['epochs']=5  #The number of Epochs is the number of times you go through the full dataset.\n",
    "args['lr']=0.005 #Learning rate is how fast it will decend.\n",
    "args['seed']=1 #random seed\n",
    "args['log_interval']=20\n",
    "args['cuda']=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_5UuOjjrnogR",
    "outputId": "49e3b51d-682b-4642-d5ad-7557e5306a4f"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=args['test_batch_size'],\n",
    "                                          shuffle=True, num_workers=16, pin_memory=True)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=args['test_batch_size'],\n",
    "                                         shuffle=False, num_workers=16, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aG5qXPDxnUnj"
   },
   "source": [
    "Определите некоторые вспомогательные функции и классы, которые помогут нам отслеживать статистику и точность данных обучения/тестирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WetzHpQybN1k"
   },
   "outputs": [],
   "source": [
    "def print_size_of_model(model):\n",
    "    \"\"\" Prints the real size of the model \"\"\"\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
    "    os.remove('temp.p')\n",
    "\n",
    "def load_model(quantized_model, model):\n",
    "    \"\"\" Loads in the weights into an object meant for quantization \"\"\"\n",
    "    state_dict = model.state_dict()\n",
    "    model = model.to('cpu')\n",
    "    quantized_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Kgl8VuSAUsDA"
   },
   "outputs": [],
   "source": [
    "def train(model, epoch, loss_fn, optimizer, train_loader):\n",
    "    model.train()\n",
    "    if  args['cuda']:\n",
    "        model.cuda()\n",
    "    else:\n",
    "        model.to('cpu')\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if args['cuda']:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "\n",
    "        loss = loss_fn(output, target)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        #Print out the loss periodically.\n",
    "        if batch_idx % args['log_interval'] == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    import time\n",
    "\n",
    "    start = time.time()\n",
    "    if  args['cuda']:\n",
    "        model.cuda()\n",
    "    else:\n",
    "        model.to('cpu')\n",
    "\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        if args['cuda']:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        #data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
    "\n",
    "\n",
    "\n",
    "    end = time.time()\n",
    "    acc = 100. * correct / len(test_loader.dataset)\n",
    "    print('\\nTest set:  Accuracy: {}/{} ({:.0f}%)  Time: {}\\n'.format(correct, len(test_loader.dataset),acc, end - start))\n",
    "\n",
    "    return acc\n",
    "\n",
    "\n",
    "def train_and_eval(model, train_loader, test_loader):\n",
    "    if args['cuda']:\n",
    "        model.cuda()\n",
    "\n",
    "    history = []\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args['lr'])\n",
    "    for epoch in range(1, args['epochs'] + 1):\n",
    "\n",
    "        train(model, epoch, loss_fn, optimizer, train_loader)\n",
    "        acc = test(model, test_loader)\n",
    "        history.append(acc)\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nyHUiOp8T411"
   },
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, q=False):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, 3, stride=1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(8, 8, 3, stride=5, bias=False)\n",
    "        self.fc1 = nn.Linear(32, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 10)\n",
    "\n",
    "        self.q = q\n",
    "        if self.q:\n",
    "            self.quant = QuantStub()\n",
    "            self.dequant = DeQuantStub()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if self.q:\n",
    "          x = self.quant(x)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = torch.flatten(x, 1)\n",
    "        F.relu(x)\n",
    "        x = self.fc1(x)\n",
    "        output = self.fc2(x)\n",
    "\n",
    "        if self.q:\n",
    "          output = self.dequant(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l62CkyIwtSOv"
   },
   "source": [
    "Определим простую CNN, которая классифицирует изображения MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W9_LdxSTb3BJ",
    "outputId": "c017d805-6e2e-4615-d724-c8e17f841e59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 0.176511\n"
     ]
    }
   ],
   "source": [
    "model = SimpleCNN(q=False)\n",
    "print_size_of_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HixhBHaqtmZU",
    "outputId": "653d7538-75c6-492e-cdac-1c0fdf98a024"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/torch/nn/modules/conv.py:459: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.304790\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 1.114714\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.693313\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.695130\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.637412\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.654544\n",
      "\n",
      "Test set:  Accuracy: 8305/10000 (83%)  Time: 0.866278886795044\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.588512\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.531931\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.555876\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.479359\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.439697\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.481069\n",
      "\n",
      "Test set:  Accuracy: 8532/10000 (85%)  Time: 0.7021305561065674\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.488484\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.411793\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.493540\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.502778\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.524337\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.487781\n",
      "\n",
      "Test set:  Accuracy: 8630/10000 (86%)  Time: 0.7855691909790039\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.411659\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.440225\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.411895\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.472580\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.426819\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.403862\n",
      "\n",
      "Test set:  Accuracy: 8741/10000 (87%)  Time: 0.8119614124298096\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.384656\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.432626\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.392653\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.502303\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.435610\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.390640\n",
      "\n",
      "Test set:  Accuracy: 8779/10000 (88%)  Time: 0.797203779220581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hist = train_and_eval(model, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Lp-ElDsrKua"
   },
   "source": [
    "### Post-training quantization\n",
    "\n",
    "Определим новую архитектуру квантовой сети, в которой мы также определим заглушки квантования и деквантования, которые будут важны в начале и в конце.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X-nQWDXrhItv",
    "outputId": "8b824830-d873-4dbc-f3ef-62732c37d15e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set:  Accuracy: 8779/10000 (88%)  Time: 0.8252761363983154\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(87.7900)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qmodel = SimpleCNN(q=True)\n",
    "\n",
    "load_model(qmodel, model)\n",
    "\n",
    "test(qmodel, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wQQRNAEGYVUe",
    "outputId": "e8cdaeca-5526-447f-bfb6-f95cc50d2053"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 0.176575\n"
     ]
    }
   ],
   "source": [
    "print_size_of_model(qmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qiaQkj6wJuC6"
   },
   "source": [
    "Статическое квантование после обучения включает в себя не только преобразование весов из числа с плавающей запятой в целое число, как при динамическом квантовании, но и выполнение дополнительных\n",
    "этап первой подачи пакетов данных через сеть и вычисления результирующих распределений различных активаций (в частности,\n",
    "это делается путем вставки модулей наблюдателей в разные\n",
    "точки, записывающие эти данные). Эти распределения затем используются для определения того, как конкретно следует квантовать различные активации.\n",
    "время вывода (простым методом было бы просто разделить весь диапазон активаций на 256 уровней.\n",
    "Важно отметить, что этот дополнительный шаг позволяет нам передавать квантованные значения между операциями вместо преобразования этих значений в числа с плавающей запятой, а затем обратно в целые числа между каждой операцией.\n",
    "что приводит к значительному ускорению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ctrtCLGZALGV",
    "outputId": "26ed9550-0fb6-40cd-9f82-0305caec446f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})\n"
     ]
    }
   ],
   "source": [
    "qmodel.qconfig = torch.quantization.default_qconfig\n",
    "print(qmodel.qconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x-ZaMV4bUb6-",
    "outputId": "165cc74e-29a5-4748-cf65-97cf5fa8d2f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set:  Accuracy: 52011/60000 (87%)  Time: 7.279160022735596\n",
      "\n",
      "Post Training Quantization Prepare: Inserting Observers\n",
      "\n",
      " Conv1: After observer insertion \n",
      "\n",
      " Conv2d(\n",
      "  1, 8, kernel_size=(3, 3), stride=(1, 1), bias=False\n",
      "  (activation_post_process): MinMaxObserver(min_val=-1.812164068222046, max_val=1.812164068222046)\n",
      ")\n",
      "####################\n",
      "\n",
      "Test set:  Accuracy: 52011/60000 (87%)  Time: 7.016843557357788\n",
      "\n",
      "\n",
      "Test set:  Accuracy: 52011/60000 (87%)  Time: 7.141284704208374\n",
      "\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      " Conv1: After fusion and quantization \n",
      "\n",
      " QuantizedConv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), scale=0.028538016602396965, zero_point=64, bias=False)\n",
      "Size of model after quantization\n",
      "Size (MB): 0.051583\n"
     ]
    }
   ],
   "source": [
    "# qmodel.to('cpu')\n",
    "args['cuda']=False\n",
    "\n",
    "qmodel.qconfig = torch.quantization.default_qconfig\n",
    "print(qmodel.qconfig)\n",
    "\n",
    "torch.quantization.prepare(qmodel, inplace=True)\n",
    "test(qmodel, train_loader)\n",
    "print('Post Training Quantization Prepare: Inserting Observers')\n",
    "print('\\n Conv1: After observer insertion \\n\\n', qmodel.conv1)\n",
    "\n",
    "print('#'*20)\n",
    "\n",
    "\n",
    "print('Post Training Quantization: Calibration done')\n",
    "torch.quantization.convert(qmodel, inplace=True)\n",
    "print('Post Training Quantization: Convert done')\n",
    "print('\\n Conv1: After fusion and quantization \\n\\n', qmodel.conv1)\n",
    "print(\"Size of model after quantization\")\n",
    "print_size_of_model(qmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2921308225966303"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.051583/0.176575"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LxBwCjf41qPz",
    "outputId": "9bf12610-7f38-476c-935f-52c5e5b9cac1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set:  Accuracy: 8741/10000 (87%)  Time: 0.9581553936004639\n",
      "\n"
     ]
    }
   ],
   "source": [
    "args['cuda']=False\n",
    "\n",
    "a = test(qmodel, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xXMz5kK43OWv",
    "outputId": "4b260c71-0e03-4495-b27b-66742e85fdd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 0.051583\n"
     ]
    }
   ],
   "source": [
    "print_size_of_model(qmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rEU8Ck0KBlf5",
    "outputId": "2459e43b-dc4e-4c00-c458-eaba30b9b578"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 0.176511\n"
     ]
    }
   ],
   "source": [
    "print_size_of_model(model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
